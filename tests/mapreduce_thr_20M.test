[test_case]
test = perfrunner.tests.mapreduce.MapreduceQueryThroughputTest
title = Query throughput (qps), 1 bucket x 20M x 2KB, non-DGM, 4 x 1 views, 2500 mutations/sec/node
summary = Read-heavy query test (80/20), 4 nodes, 1 bucket x 100M x 2KB, DGM, 4 x 1 views, 2500 mutations/sec/node, unbounded qps
larger_is_better = true

[stats]

[cluster]
mem_quota = 40960
initial_nodes = 4
num_buckets = 1

[bucket]

[load]
items = 20000000
size = 2048
workers = 20

[mapreduce]
indexes =
    A::{"views":{"id_by_city":{"map":"function(doc, meta) {emit(doc.city, null);}"}}}
    B::{"views":{"name_and_email_by_category_and_coins":{"map":"function(doc, meta) {emit(doc.city, [doc.name, doc.email]);}"}}}
    C::{"views":{"id_by_realm_and_coins":{"map":"function(doc, meta) {emit([doc.realm, doc.coins], null);}"}}}
    D::{"views":{"name_and_email_by_city":{"map":"function(doc, meta) {emit(doc.city, [doc.name, doc.email]);}"}}}
view_names =
    A::id_by_city
    B::name_and_email_by_category_and_coins
    C::id_by_realm_and_coins
    D::name_and_email_by_city
workers = 24

[access]
creates = 4
reads = 80
updates = 12
deletes = 4
throughput = 10000
items = 20000000
workers = 24
time = 7200

[worker_settings]
